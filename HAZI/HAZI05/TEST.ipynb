{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np\\nimport seaborn as sns\\nfrom typing import Tuple\\nfrom scipy.stats import mode\\nfrom sklearn.metrics import confusion_matrix\\nimport pandas as pd\\nfrom HAZI05 import KNNClassifier'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''import numpy as np\n",
    "import seaborn as sns\n",
    "from typing import Tuple\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from HAZI05 import KNNClassifier'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class KNNClassifier:\n",
    "\n",
    "    @property\n",
    "    def k_neighbors(self):  # 1\n",
    "\n",
    "        return self.k\n",
    "\n",
    "    def __init__(self, k: int, test_split_ratio: float) -> None:\n",
    "\n",
    "        self.k = k\n",
    "        self.test_split_ratio = test_split_ratio\n",
    "\n",
    "        self.x_test, self.y_test = None, None\n",
    "\n",
    "        self.x_train, self.y_train = None, None\n",
    "\n",
    "        self.y_preds = None\n",
    "\n",
    "    def train_test_split(self, features: pd.DataFrame, labels: pd.DataFrame) -> None:  # 3\n",
    "\n",
    "        test_size = int(features.shape[0] * self.test_split_ratio)\n",
    "\n",
    "        train_size = features.shape[0] - test_size\n",
    "\n",
    "        assert features.shape[0] == test_size + train_size, \"Size mismatch!\"\n",
    "\n",
    "        self.x_train, self.y_train = features.iloc[:train_size,\n",
    "                                                   :], labels.iloc[:train_size].reset_index(drop=True)\n",
    "\n",
    "        self.x_test, self.y_test = features.iloc[train_size:train_size +\n",
    "                                                 test_size, :], labels.iloc[train_size:train_size + test_size].reset_index(drop=True)\n",
    "\n",
    "    def euclidean(self, element_of_x: pd.DataFrame) -> pd.DataFrame:  # 4\n",
    "\n",
    "        return np.sqrt(np.sum((self.x_train - element_of_x)**2, axis=1))\n",
    "\n",
    "\n",
    "    def predict(self,x_test:pd.DataFrame) -> pd.Series: #5\n",
    "        labels_pred = []\n",
    "        for idx, x_test_element in x_test.iterrows():\n",
    "            distances = self.euclidean(x_test_element)\n",
    "            distances = pd.concat([distances, self.y_train], axis=1).sort_values(by=0)\n",
    "            label_pred = mode(distances.iloc[:self.k,1],keepdims=False).mode\n",
    "            labels_pred.append(label_pred)\n",
    "        self.y_preds = pd.DataFrame(labels_pred)\n",
    "\n",
    "    def accuracy(self) -> float:  # 6\n",
    "        true_positive = (self.y_test.iloc[:, 0] == self.y_preds.iloc[:, 0]).sum()\n",
    "\n",
    "        return true_positive / self.y_test.shape[0] * 100\n",
    "\n",
    "    def confusion_matrix(self):  # 7\n",
    "        conf_matrix = confusion_matrix(self.y_test, self.y_preds)\n",
    "\n",
    "        return conf_matrix\n",
    "\n",
    "    def best_k(self):\n",
    "        ret = tuple((1, -1))\n",
    "        for i in range(1, 21):\n",
    "            self.k = i\n",
    "            self.predict(self.x_test)\n",
    "            acc = self.accuracy()\n",
    "            if acc > ret[1]:\n",
    "                ret = (self.k, acc.round(2))\n",
    "\n",
    "        return ret\n",
    "\n",
    "    @staticmethod\n",
    "    def load_csv(csv_path: str) -> Tuple[pd.DataFrame, pd.DataFrame]:  # 2\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df = df.sample(frac=1, random_state=42, ignore_index=True)\n",
    "        x_ = df.iloc[:, :8]\n",
    "        # pd.DataFrame(df['Outcome']) dupla [[]] = dataframet ad vissza series helyett\n",
    "        y_ = df[['Outcome']]\n",
    "\n",
    "        return x_, y_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 63.4), (2, 67.97), (4, 71.9), (6, 74.51), (9, 75.16), (18, 75.16)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNNClassifier(3, 0.2)\n",
    "x, y = knn.load_csv(r'C:\\Users\\darab\\source\\repos\\BEVADAT\\QYZF3M_BEVADAT2022232\\HAZI\\HAZI05\\diabetes.csv')\n",
    "\n",
    "knn.train_test_split(x, y)\n",
    "\n",
    "knn.predict(knn.x_test)\n",
    "\n",
    "knn.best_k()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
